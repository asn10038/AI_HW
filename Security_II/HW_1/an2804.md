# Security II Homework
---

### 1) CBC Mode Splicing

#### a) Give an example of a type of file where the plain text won't show the file has been tampered with
  * In the decrypted version of the tampered file only 1 block of plaintext is garbled. In an *image file*
  one block of plain text may only be a few pixels so someone looking at the decrypted image probably won't notice
  the corruption.

#### b) What can be sent with the cipher text to detect tampering?
  * A message authentication code (MAC) can be used to detect tampering.

#### c) What mode of encryption includes this tampering detection mechanism?
  * CMAC and GMAC are modes of encryption that include a MAC at the end of the message for authentication.

### 2) For CTR mode, is it ever possible to splice ciphertext from two different files together and not have the splice detected when the files are decrypted? If yes, how/why and explain under what conditions. If not, why not?
  * I think the answer yes. Ctr mode works by encrypting `nonce||i` (where i is a token unique to the sequence number and nonce is a one time key), and then `XOR'ing` that value with the plain text (p<sub>i</sub>)to produce the cipher text (c<sub>i</sub>). CTR mode is malleable meaning that if the cipher text is changed the decryption will still be considered valid. This makes sense because changing the ciphertext doesn't influence the `E(nonce||i)` block required to do decryption. Of course blindly changing the cipher text will likely result in garbage after decryption.
  However splicing together ciphertexts so that nothing looks wrong is harder. The spliced ciphertext blocks must be created using the same `E(nonce||i)` block as the original otherwise the decryption will be deemed invalid. Furthermore the decrypted plain text must also look normal to humans. I think in a large file like an image or a video splicing valid ciphertext into the message could go undetected to the human eye as the human wouldn't notice some small inconsistencies in the resulting plaintext.

### 3)  Pros/Cons of standardization (Estream competitions)

#### a) What is the disadvantage of having different recommended standards for software and hardware?
  If there is a different standard for hardware and software, that means both the encrypting and the decrypting parties must act either in hardware or software. If a group only has access to either hardware or software they can only communicate with other groups who have access to the same cryptographic mechanisms.

#### b) What is the disadvantage of having multiple standards for a specific algorithm type in general?
  If there is more than one standard for the same algorithm type this can lead to confusion. Parties in communication that use different standards, even for the same algorithm type, can't communicate if the standards conflict in some way.

#### c) What is an advantage to having multiple standard algorithms?
  Algorithms all come with pros and cons. Even if they accomplish the same thing in theory, there are often practical implications that make one algorithm a better choice than the others for a specific situations.

### 4) Quantum Cryptography

#### a) Why is it necessary to start developing standards for crypto algorithms that will run on today's computers but remain secure when quantum computation is practical?
  Updating infrastructure takes a long time. When quantum computation is practical many of today's computers will be the ones using the crypto algorithms.

#### b) If the timeline holds how many years will be from the time the CFP was announced (not the CFP release date) to the time draft standards are available (latest year listed)?
  The call for proposals was announced in Fall of 2016. Based on the timeline listed [here](csrc.nist.gov/Projects/Post-Quantum-Cryptography/Workshops-and-Timeline) the draft standards will be available by 2024 the latest. Assuming the end of 2024 that would be 8 years between CFP and available algorithms.

#### c) For round 2 what 2 categories of algorithms are listed? What candidate algorithms in each category?
  For **Public-key** Encryption and Key-establishment Algorithms:
  * BIKE
  * Classic McEliece
  * Crystals-Kyber
  * FrodoKEM
  * HQC
  * LACAcrypt
  * NTRU
  * NTRU Prime
  * NTS-KEM
  * ROLLO
  * Round5
  * RQC
  * SABER
  * SIKE
  * Three Bears

  For **Digital Signature Algorithms**:
  * CRYSTALS-DILITHIUM
  * FALCON
  * GeMSS
  * LUOV
  * MQDSS
  * Picnic
  * qTESLA
  * Rainbow
  * SPHINCS+

#### d) What is the concern with having a large number of submissions?
  Having a large number of submissions means that it takes a long time to evaluate which submission is the winner. Also a large number of submissions increases the evaluation complexity which means that a potential weakness might be missed somewhere.

#### e) What is the benefit of having a large number of submissions?
  By having a large number of submissions it ensures that as many solutions as possible are considered so it increases the chances the best solution will be found. Also by comparing many solutions it encourages many different approaches to the same problem. Some of which will be better than others for different situations.

### 5) Public Key Crypto questions

#### a) Consider a cipher using a key, *K* of length *b* to encrypt data. Given plaintext *P* containing *n* bytes why is it necessary that the cipher be implemented so that the time the cipher takes to encrypt *P* be the same regardless of the value of *K*.
  If the cipher takes different amounts of time based on the value of *K* this could result in side channel attacks based on the timing. In theory the attacker could learn information about *K* based on the amount of time it took for the encryption to take place.

#### b) Give an example of a public key algorithm where the time to encrypt can vary and explain why the encryption time may vary
  RSA encryption depends on mathematical operations involving a series of secret parameters. Particularly when dealing with the exponent involved. Depending on what the values of the secret parameters are it may take different amounts of time to do the encryption and decryption because computers make performance optimizations when doing the calculations. Values that are particularly amenable to being optimized will finish far faster than other values. This leaks information about what the secret parameters are.

#### c) In a particular implementation of AES why might the answer to part a be relevant?
  Table lookups are quick and round function computation is slow. When AES can look up data in tables these computations will happen quickly, but will happen slowly if the CPU has to actually compute the values. If an attacker monitors how long computations take they know which values are being looked up in tables and which are being computed. Since the tables are in memory and unencrypted the timing discrepancy leaks information to the attacker about what values are used in the encryption.

### 6) Kerberos

#### a) Why is Alice sure she is talking to Bob?
