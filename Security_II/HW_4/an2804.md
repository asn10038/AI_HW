Anthony Saieva Narin

# Homework 4 Report
---

### 1) Meltdown and Spectre

#### a) What feature of processors was added that allowed for the Meltdown and Spectre attacks?
* **Out of order execution** allows for these attacks to take place. Modern processors allow instructions
to be executed out of order to make use of idle cycles while time consuming operations are taking place.

#### b) From the meltdown paper why can all of the memory be read from Linux and OS X devices but only a subset of memory can be read from Windows devices?
Windows and Linux/OSX devices manage memory differently. Linux/OSX map the entire physical memory into a predefined kernel space set of virtual addresses and rely on the CPU differentiating between privelaged and non privelaged instructions to manage access to these locations. Windows memory management doesn't map the entire physical memory into the virtual address space but instead map a large fraction of it. The meltdown attack leaks secrets bypassing privelaged mode isolation to read the entire virtual memory address space. Therefore it can read any physical memory mapped including physical memory of any other process and the kernel. However it can't read memory that isn't mapped into the virtual address space at all. In the case of Linux/OSX where everything is mapped into memory Meltdown can access everything, but on Windows the attack can't access memory that hasn't been mapped into the process' address space.

#### c) How does the Spectre attack differ from the Meltdown attack?
* Both Meltdown and Spectre rely on triggering speculative execution with a malicious read access, but Meltdown achieves this by manipulating the execution surrounding instructions that cause a trap, while Spectre achieves this by manipulating the branch predictors. Meltdown makes an illegal access after an exception is thrown while Spectre trains the branch predictor to execute a set of transient instructions and then forces an illegal read to happen in that set of transient instructions. (Transient instructions can be thought of as instructions that are executed out of order but it hasn't been determined whether they should be used or not)
* Meltdown exploits a privelage escalation flaw in Intel and related CPU families while Spectre works with any CPU that has branch prediction which includes non intel chips like AMD and ARM processors.
* Meltdown can be mitigated by mapping minimal randomized kernel space memory into user space (KAISER + KASLR), but mitigation for Spectre is far more nuanced. One could stop speculative execution altogether but this would incur a large performance hit. The authors suggest that speculative execution can be halted on sensitive execution paths, but also say that sound solutions require changes to processor designs and updates to instruction sets (ISAs).
* Meltdown allows an attacker to read kernel space data and just about everything on the machine while Spectre can only access userspace information. As mentioned earlier Meltdown can read the entire virtual memory space including privileged portions of the address space. Meltdown can do this because of a race condition that stores information based on data from privileged reads in the cache before an error is thrown. Spectre on the other hand trains branch predictors such that illegal reads happen speculatively but reads in the kernel space will still throw an error. Spectre doesn't exploit the race condition in the error handling so this defense mechanism is still in place. As such when Spectre tries to read the privileged kernel space the error is still thrown and Spectre can't  access it. In short Meltdown has access to kernel memory reads while Spectre does not.
* Because Spectre Involves training the branch prediction units it requires normal function executions in between malicious function executions. Meltdown works after a program triggers a single trap instruction. As such the speed of Spectre dumping data is listed at around 10KB/s while Meltdown is measured in the 100's of KB/s. The meltdown paper terms this as  "Spectre requires tailoring of the software environment".

### 2) Stack Canaries
###  What are canaries and how do they help prevent attacks due to buffer overflow?
 Buffer overflow attacks generally work by rewriting information on the stack. Often times the return address is re written to take control of code execution. However to do so the attacker must overwrite everything else on the stack between the variable that overflows and the return address. To defend against this compilers insert a canary value on the stack between the local variables that are exploited and the return address. As such if the attacker wants to overwrite the return address they also have to overwrite the canary value. If the canary value is changed the program knows a buffer overflow has taken place and will exit.

Of course if the attacker can guess the canary value this doesn't work so canary values must be chosen wisely.Some implementations choose canary values randomly at program startup. Another approach is to use terminator characters as the canary values so the attacker cannot use string functions to corrupt the stack since string functions stop writing at the first null byte.

#### What is one type of attack stack canaries don't prevent
Stack canaries can't protect against Integer Overflow attacks. Integer overflow attacks are when the value in a memory location gets bigger than the maximum value a memory location can hold and the value wraps around. One possible result is the value stored in that location goes from being very high to very low.
One hypothetical example of this could be on an online shopping application. If the price of an order goes over $X the integer overflows and the price becomes $0. The order would remain the same but the price would be changed.
This doesn't write to unexpected locations on the stack so stack canaries won't detect that something has been incorrectly written.

### 3) How does return oriented programming work? -- This needs to be reworked
Return oriented programming hijacks control without executing custom code. Instead it re-uses code that has already been loaded into the address space. If an attacker can overwrite the return address, they can force the vulnerable function to return to any place in the address space including shared libraries. The remaining problem is how to chain existing function calls together such that an attacker can execute arbitrary code.

To solve this problem return oriented programming (ROP) takes advantage of code snippets called *gadgets*. Gadgets are pieces of code that end in a return instruction. Since the attacker can return to any address in the address space the attacker can return to any arbitrary point in the middle of any function. Chaining these together allows for arbitrary code execution.

Since the attacker controls the stack if they chain together gadgets that pop a source and target address (`pop %edx; pop %ecx;`) from the stack with a gadget to write to an arbitrary memory location (`store %edx %ecx`) they can create an arbitrary write primitive. Another common attack is to return to some place in libc. Chaining gadgets together an attacker can push a string already present in the address space. Something like `/bin/sh` and then return to the starting point of the `exec` function call. This gives an attacker a shell on the machine. The last piece the attacker needs to figure out is what addresses to return to so they can execute the functions and gadgets required to carry out the attack. Address space layout randomization randomizes the memory layout at program run time which helps mitigate these types of attacks.


### 4) What are pointer authentication codes and what type(s) of attacks are they trying to prevent? What is a type of attack that the Qualcomm PAC does not fully prevent per the assigned reading?
On modern machines addresses and pointers are 64 bits, but the virtual memory space in practice is usually far smaller than 64 bits. As such there are extra bits on the pointer that don't need to be used to find the address. Pointer authentication leverages this property and uses these extra bits to form a cryptographically secure *pointer authentication code*. If someone wants to rewrite the pointer they have to rewrite the pointer authentication code as well.

For attacks like stack buffer overflows, when the attacker tries to overwrite the return address of the function if the PAC of the newly written address is incorrect then it will indicate something has been tampered with and execution will end.

Stack canaries function in a similar matter, but remain vulnerable to memory disclosure vulnerabilities. If the attacker knows the canary value they can re write it appropriately. Because PAC's are cryptographically generated based on context specific information (like stack addresses) and the keys are not accessible from usermode, the attacker cannot determine the PAC from most memory disclosure vulnerabilities.

Brute forcing the PAC's is as hard as the length of the PAC. The search space of the PAC tends to be in the 2048 range so this isn't easy. Therefoe on most systems if more than one pointer needs to be guessed the performance hit is so great that this becomes infeasible. However there are concerns about child processes having the same pointer authentication keys as the parent process. In the event the attacker can spawn a large number of child processes, they can attempt to brute force the authentication keys of the parent process. In the event the parent is a privileged process and the children are unprivileged the attacker could then defeat PAC in the parent process. To mitigate this risk the authors leave it to kernel designers to apply a software patch.

One example of an attack that PAC's don't protect fully against is Data Only attacks. If the attacker can make themselves root through a kernel exploit, the attacker can combine this with a remote exploit that changes the authenticated flag in memory to true and bypass a password check. This attack took place without modifying any pointers so PAC's don't completely protect against arbitrary write primitives.

ARM does provide the PACGA instruction that will encrypt data related pointers. Authenticating sensitive data pointers and data structures can limit the attacker's abilities (heap meta data, pointers to sensitive user data etc).

One attack that the authors reference that PAC's don't protect against at all is an interesting pointer re-use attack. Since PAC's for return addresses are dependent upon their position on the stack, if the attacker can read the return addresses on the stack and gather the PAC's associated with stack position they can reuse  the PAC's for those addresses in a different context. Chaining these together an attacker can execute a ROP payload.

### 5) How can multiple protocols for IoT devices and multiple standards efforts (committees/organizations) contribute to security issues even as the organizations try to address security?
Because the standards are competing and not collaborating there is great pressure to push standards to market since the first standard is most likely to be adopted. This could lead to rushed security protocols that haven't been fully vetted and might contain bugs.

Different standards and different protocols lead to miscommunication and misconfiguration issues between devices. If devices A and B can only communicate if authentication is disabled the user may be forced to disable authentication.

### 6) Find an example of an attack against a vehicle's software or hardware other than the attacks on Jeeps.
Link to the explanation: https://www.pentestpartners.com/security-blog/gone-in-six-seconds-exploiting-car-alarms/

In this attack the pentesters attacked two high tech after market alarm systems that people buy for their cars. The two alarm vendors under investigation are Viper and Pandora. The attack is remarkably simple. The API doesn't require authentication to update the linked email address. The attacker can update the linked email address directly through unauthenticated API calls then send a password reset to the newly linked email address. Once the account has been hijacked the attacker can geo-locate the vehicle, stop the car, and unlock the doors. Both alarms use the third party CalAmp as a backend service which has the underlying security vulnerability. The security vulnerability in the backend was discovered first then the researchers performed the exploit on the two front end services as a proof of concept. 

### 7) How does the collection of information on individuals/users by companies contribute to the potential for computer-security related attacks?
* Learning information about individuals can provide information for social engineering attacks (i.e. what types of phishing mail to craft etc).
* If known location there's the opportunity for man in the middle on wifi or intercepting phone/laptop info.
* Learning the location of a person also leads to physical security risks.
* All of the information collected needs to be stored somewhere. If the place where the information is stored is hacked then all of the that user data becomes public.
* The information available may leak device specific information which can guide attackers. For example if a certain version of an OS is vulnerable and the attacker can look for people that have a certain OS installed on their device.
